{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_Yuy55M-LF-"
      },
      "source": [
        "# Preference Alignment with Odds Ratio Preference Optimization (ORPO)\n",
        "\n",
        "This notebook will guide you through the process of fine-tuning a language model using Odds Ratio Preference Optimization (ORPO). We will use the SmolLM2-135M model which has **not** been through SFT training, so it is not compatible with DPO. This means, you cannot use the model you trained in [1_instruction_tuning](../../1_instruction_tuning/notebooks/sft_finetuning_example.ipynb).\n",
        "\n",
        "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
        "     <h2 style='margin: 0;color:blue'>Exercise: Aligning SmolLM2 with ORPOTrainer</h2>\n",
        "     <p>Take a dataset from the Hugging Face hub and align a model on it. </p>\n",
        "     <p><b>Difficulty Levels</b></p>\n",
        "     <p>üê¢ Use the `trl-lib/ultrafeedback_binarized` dataset</p>\n",
        "     <p>üêï Try out the `argilla/ultrafeedback-binarized-preferences` dataset</p>\n",
        "     <p>ü¶Å Try on a subset of mlabonne's `orpo-dpo-mix-40k` dataset</p>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hkHn6rQ-LF_"
      },
      "source": [
        "## Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwNxh0pCQhfI",
        "outputId": "e4c288e1-2fa3-4717-d9dd-ae3ec0b91e3b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        ")\n",
        "from trl import ORPOConfig, ORPOTrainer, setup_chat_format\n",
        "\n",
        "# Authenticate to Hugging Face\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(token=input(\"Please give your huggingface key: \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged in as: {'type': 'user', 'id': '66f9ceca46d413c380d53ff3', 'name': 'AMindToThink', 'fullname': 'Matthew Khoriaty', 'email': 'matthewkhoriaty@gmail.com', 'emailVerified': True, 'canPay': False, 'periodEnd': None, 'isPro': False, 'avatarUrl': '/avatars/44baa1c81b0e87ac5ff27c43173423d4.svg', 'orgs': [], 'auth': {'type': 'access_token', 'accessToken': {'displayName': 'zach_AMindToThink_write', 'role': 'write', 'createdAt': '2025-02-25T21:02:51.453Z'}}}\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import whoami\n",
        "try:\n",
        "    username = whoami()\n",
        "    print(f\"Logged in as: {username}\")\n",
        "except Exception as e:\n",
        "    print(\"Not logged in or error retrieving user information.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbtXToR--LGA"
      },
      "source": [
        "## Format dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AQT08S8j-LGA",
        "outputId": "23d86e61-f7ba-4d65-92be-7382f4d4d7f3"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "\n",
        "# TODO: ü¶Åüêï change the dataset to one of your choosing\n",
        "dataset = load_dataset(path=\"trl-lib/ultrafeedback_binarized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "u5YJ0Ttm-LGB"
      },
      "outputs": [],
      "source": [
        "# TODO: üêï If your dataset is not represented as conversation lists, you can use the `process_dataset` function to convert it.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKzUyZOI-LGB"
      },
      "source": [
        "## Define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "w2kGBNStQoUd"
      },
      "outputs": [],
      "source": [
        "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
        "\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        ")\n",
        "assert device == 'cuda'\n",
        "# Model to fine-tune\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    pretrained_model_name_or_path=model_name,\n",
        "    torch_dtype=torch.float32,\n",
        ").to(device)\n",
        "model.config.use_cache = False\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model, tokenizer = setup_chat_format(model, tokenizer)\n",
        "\n",
        "# Set our name for the finetune to be saved &/ uploaded to\n",
        "finetune_name = \"SmolLM2-FT-ORPO_example\"\n",
        "finetune_tags = [\"smol-course\", \"module_1\"]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jjmt0Pc1-LGB"
      },
      "source": [
        "## Train model with ORPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "AWDwJe7_Qqgb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cs29824/matthew/interpretable-fine-tuning/.venv/lib/python3.11/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "orpo_args = ORPOConfig(\n",
        "    # Small learning rate to prevent catastrophic forgetting\n",
        "    learning_rate=8e-6,\n",
        "    # Linear learning rate decay over training\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    # Maximum combined length of prompt + completion\n",
        "    max_length=1024,\n",
        "    # Maximum length for input prompts\n",
        "    max_prompt_length=512,\n",
        "    # Controls weight of the odds ratio loss (Œª in paper)\n",
        "    beta=0.1,\n",
        "    # Batch size for training\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    # Helps with training stability by accumulating gradients before updating\n",
        "    gradient_accumulation_steps=4,\n",
        "    # Memory-efficient optimizer for CUDA, falls back to adamw_torch for CPU/MPS\n",
        "    optim=\"paged_adamw_8bit\" if device == \"cuda\" else \"adamw_torch\",\n",
        "    # Number of training epochs\n",
        "    # num_train_epochs=1,\n",
        "    # When to run evaluation\n",
        "    evaluation_strategy=\"steps\",\n",
        "    # Evaluate every 20% of training\n",
        "    eval_steps=0.2,\n",
        "    # Log metrics every step\n",
        "    logging_steps=1,\n",
        "    # Gradual learning rate warmup\n",
        "    warmup_steps=10,\n",
        "    # Disable external logging\n",
        "    report_to=\"wandb\",\n",
        "    # Where to save model/checkpoints\n",
        "    output_dir=\"./results/\",\n",
        "    # Enable MPS (Metal Performance Shaders) if available\n",
        "    use_mps_device=device == \"mps\",\n",
        "    hub_model_id=finetune_name,\n",
        "    # bf16=True,\n",
        "    num_train_epochs=(1/4*.25),# I decided to target 15 minutes for this example. 1 epochs / 4 hours times .25 hours \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "JUTYdQmf-LGB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cs29824/matthew/interpretable-fine-tuning/.venv/lib/python3.11/site-packages/trl/trainer/orpo_trainer.py:275: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
            "  warnings.warn(\n",
            "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
          ]
        }
      ],
      "source": [
        "trainer = ORPOTrainer(\n",
        "    model=model,\n",
        "    args=orpo_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    processing_class=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñÜ‚ñá‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/log_odds_chosen</td><td>‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñá‚ñÉ‚ñÜ‚ñÅ‚ñá‚ñÑ‚ñÖ‚ñà‚ñÉ‚ñÖ‚ñÑ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÜ</td></tr><tr><td>train/log_odds_ratio</td><td>‚ñÑ‚ñÉ‚ñà‚ñÜ‚ñÑ‚ñá‚ñÉ‚ñÖ‚ñÅ‚ñá‚ñÉ‚ñÖ‚ñá‚ñÉ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñÖ‚ñÑ‚ñá‚ñá‚ñÖ‚ñá‚ñÜ</td></tr><tr><td>train/logits/chosen</td><td>‚ñÜ‚ñÑ‚ñÉ‚ñÜ‚ñá‚ñÑ‚ñá‚ñá‚ñÅ‚ñÜ‚ñÖ‚ñà‚ñÖ‚ñÜ‚ñÖ‚ñÅ‚ñÖ‚ñÇ‚ñÑ‚ñá‚ñÜ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÖ‚ñÉ</td></tr><tr><td>train/logits/rejected</td><td>‚ñÜ‚ñÑ‚ñÑ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñÇ‚ñÖ‚ñÑ‚ñá‚ñà‚ñÅ‚ñÇ‚ñÅ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñÖ‚ñÑ‚ñÅ‚ñÑ‚ñÉ</td></tr><tr><td>train/logps/chosen</td><td>‚ñÜ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñà‚ñÑ‚ñÖ‚ñÇ‚ñÜ‚ñÖ‚ñÅ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñà</td></tr><tr><td>train/logps/rejected</td><td>‚ñÜ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÇ‚ñá‚ñÜ‚ñà‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñá</td></tr><tr><td>train/loss</td><td>‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÇ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÇ</td></tr><tr><td>train/nll_loss</td><td>‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÅ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÇ</td></tr><tr><td>train/rewards/accuracies</td><td>‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÅ‚ñÜ‚ñÅ‚ñÜ‚ñÅ‚ñà‚ñÑ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñà‚ñá‚ñÖ‚ñÜ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñá</td></tr><tr><td>train/rewards/chosen</td><td>‚ñÜ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñà‚ñÑ‚ñÖ‚ñÇ‚ñÜ‚ñÖ‚ñÅ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñà</td></tr><tr><td>train/rewards/margins</td><td>‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñá‚ñÉ‚ñÜ‚ñÅ‚ñá‚ñÑ‚ñÑ‚ñà‚ñÉ‚ñÖ‚ñÑ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÖ</td></tr><tr><td>train/rewards/rejected</td><td>‚ñÜ‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÇ‚ñá‚ñÜ‚ñà‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñá</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>0.0139</td></tr><tr><td>train/global_step</td><td>27</td></tr><tr><td>train/grad_norm</td><td>3.44195</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/log_odds_chosen</td><td>0.22409</td></tr><tr><td>train/log_odds_ratio</td><td>-0.72773</td></tr><tr><td>train/logits/chosen</td><td>12.52754</td></tr><tr><td>train/logits/rejected</td><td>13.47893</td></tr><tr><td>train/logps/chosen</td><td>-1.88092</td></tr><tr><td>train/logps/rejected</td><td>-2.05461</td></tr><tr><td>train/loss</td><td>8.3341</td></tr><tr><td>train/nll_loss</td><td>2.01075</td></tr><tr><td>train/rewards/accuracies</td><td>0.625</td></tr><tr><td>train/rewards/chosen</td><td>-0.18809</td></tr><tr><td>train/rewards/margins</td><td>0.01737</td></tr><tr><td>train/rewards/rejected</td><td>-0.20546</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run-20250226-0444-1a02f5</strong> at: <a href='https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo/runs/zwxwsmhw' target=\"_blank\">https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo/runs/zwxwsmhw</a><br> View project at: <a href='https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo' target=\"_blank\">https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo</a><br>Synced 6 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250226_044418-zwxwsmhw/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/cs29824/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/cs29824/matthew/interpretable-fine-tuning/src/training/practice/wandb/run-20250226_045006-k53vxw4w</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo/runs/k53vxw4w' target=\"_blank\">run-20250226-0450-fb827d</a></strong> to <a href='https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo' target=\"_blank\">https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo/runs/k53vxw4w' target=\"_blank\">https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo/runs/k53vxw4w</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo/runs/k53vxw4w?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f4bc99cbf10>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "from datetime import datetime\n",
        "import uuid\n",
        "wandb.finish()\n",
        "if not os.getenv(\"WANDB_API_KEY\"):\n",
        "    wandb.login(key=input(\"Please enter your W&B API key: \"))\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.init(\n",
        "    project=\"smollm2-orpo\",\n",
        "    name=f\"run-{datetime.now().strftime('%Y%m%d-%H%M')}-{uuid.uuid4().hex[:6]}\",\n",
        "    tags=finetune_tags\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "4mRSTqv6-LGC"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='122' max='122' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [122/122 20:09, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "      <th>Rewards/chosen</th>\n",
              "      <th>Rewards/rejected</th>\n",
              "      <th>Rewards/accuracies</th>\n",
              "      <th>Rewards/margins</th>\n",
              "      <th>Logps/rejected</th>\n",
              "      <th>Logps/chosen</th>\n",
              "      <th>Logits/rejected</th>\n",
              "      <th>Logits/chosen</th>\n",
              "      <th>Nll Loss</th>\n",
              "      <th>Log Odds Ratio</th>\n",
              "      <th>Log Odds Chosen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>8.878600</td>\n",
              "      <td>2.063274</td>\n",
              "      <td>78.129300</td>\n",
              "      <td>12.799000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>-0.194836</td>\n",
              "      <td>-0.208181</td>\n",
              "      <td>0.522000</td>\n",
              "      <td>0.013346</td>\n",
              "      <td>-2.081815</td>\n",
              "      <td>-1.948357</td>\n",
              "      <td>12.274585</td>\n",
              "      <td>11.579242</td>\n",
              "      <td>1.981609</td>\n",
              "      <td>-0.816654</td>\n",
              "      <td>0.150561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>8.694100</td>\n",
              "      <td>2.034441</td>\n",
              "      <td>77.904000</td>\n",
              "      <td>12.836000</td>\n",
              "      <td>1.605000</td>\n",
              "      <td>-0.188239</td>\n",
              "      <td>-0.200956</td>\n",
              "      <td>0.512000</td>\n",
              "      <td>0.012717</td>\n",
              "      <td>-2.009562</td>\n",
              "      <td>-1.882390</td>\n",
              "      <td>11.899893</td>\n",
              "      <td>11.256330</td>\n",
              "      <td>1.954384</td>\n",
              "      <td>-0.800572</td>\n",
              "      <td>0.144660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>7.742500</td>\n",
              "      <td>2.018961</td>\n",
              "      <td>77.830900</td>\n",
              "      <td>12.848000</td>\n",
              "      <td>1.606000</td>\n",
              "      <td>-0.184731</td>\n",
              "      <td>-0.197361</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>0.012630</td>\n",
              "      <td>-1.973608</td>\n",
              "      <td>-1.847309</td>\n",
              "      <td>11.573335</td>\n",
              "      <td>10.953115</td>\n",
              "      <td>1.939778</td>\n",
              "      <td>-0.791831</td>\n",
              "      <td>0.144018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>7.200000</td>\n",
              "      <td>2.011636</td>\n",
              "      <td>77.536800</td>\n",
              "      <td>12.897000</td>\n",
              "      <td>1.612000</td>\n",
              "      <td>-0.182675</td>\n",
              "      <td>-0.195402</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>0.012727</td>\n",
              "      <td>-1.954018</td>\n",
              "      <td>-1.826746</td>\n",
              "      <td>11.315008</td>\n",
              "      <td>10.712767</td>\n",
              "      <td>1.933174</td>\n",
              "      <td>-0.784617</td>\n",
              "      <td>0.145068</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=122, training_loss=8.154225345517768, metrics={'train_runtime': 1217.7164, 'train_samples_per_second': 3.189, 'train_steps_per_second': 0.1, 'total_flos': 0.0, 'train_loss': 8.154225345517768, 'epoch': 0.06282992146259817})"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()  # Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Save the model\n",
        "trainer.save_model(f\"./{finetune_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/log_odds_chosen</td><td>‚ñà‚ñÇ‚ñÅ‚ñÇ</td></tr><tr><td>eval/log_odds_ratio</td><td>‚ñÅ‚ñÖ‚ñÜ‚ñà</td></tr><tr><td>eval/logits/chosen</td><td>‚ñà‚ñÖ‚ñÉ‚ñÅ</td></tr><tr><td>eval/logits/rejected</td><td>‚ñà‚ñÖ‚ñÉ‚ñÅ</td></tr><tr><td>eval/logps/chosen</td><td>‚ñÅ‚ñÖ‚ñá‚ñà</td></tr><tr><td>eval/logps/rejected</td><td>‚ñÅ‚ñÖ‚ñá‚ñà</td></tr><tr><td>eval/loss</td><td>‚ñà‚ñÑ‚ñÇ‚ñÅ</td></tr><tr><td>eval/nll_loss</td><td>‚ñà‚ñÑ‚ñÇ‚ñÅ</td></tr><tr><td>eval/rewards/accuracies</td><td>‚ñà‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>eval/rewards/chosen</td><td>‚ñÅ‚ñÖ‚ñá‚ñà</td></tr><tr><td>eval/rewards/margins</td><td>‚ñà‚ñÇ‚ñÅ‚ñÇ</td></tr><tr><td>eval/rewards/rejected</td><td>‚ñÅ‚ñÖ‚ñá‚ñà</td></tr><tr><td>eval/runtime</td><td>‚ñà‚ñÖ‚ñÑ‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ‚ñÑ‚ñÑ‚ñà</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ‚ñÑ‚ñÑ‚ñà</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÇ</td></tr><tr><td>train/learning_rate</td><td>‚ñÇ‚ñÑ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/log_odds_chosen</td><td>‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñá‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÜ‚ñÉ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñà‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÑ</td></tr><tr><td>train/log_odds_ratio</td><td>‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñà‚ñÜ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñá‚ñá‚ñÇ‚ñÑ‚ñÖ‚ñÅ‚ñÜ‚ñÜ‚ñÖ</td></tr><tr><td>train/logits/chosen</td><td>‚ñá‚ñÖ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñÅ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñá‚ñÅ‚ñÉ‚ñÉ</td></tr><tr><td>train/logits/rejected</td><td>‚ñà‚ñÜ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÜ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÉ</td></tr><tr><td>train/logps/chosen</td><td>‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÇ‚ñÖ‚ñÖ‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÇ‚ñá‚ñá‚ñÜ</td></tr><tr><td>train/logps/rejected</td><td>‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÅ‚ñÖ‚ñá‚ñÑ‚ñÜ‚ñÑ‚ñá‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñà‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñÇ‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñá‚ñÖ‚ñá‚ñÜ‚ñá‚ñÖ‚ñÜ</td></tr><tr><td>train/loss</td><td>‚ñá‚ñá‚ñÑ‚ñá‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñà‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñá‚ñÅ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñá‚ñÖ‚ñÇ</td></tr><tr><td>train/nll_loss</td><td>‚ñÜ‚ñá‚ñá‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÖ‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÇ‚ñÜ‚ñÖ‚ñÇ‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÅ</td></tr><tr><td>train/rewards/accuracies</td><td>‚ñÑ‚ñÜ‚ñÇ‚ñÉ‚ñá‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÇ‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñá‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñá‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÑ</td></tr><tr><td>train/rewards/chosen</td><td>‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñá‚ñÑ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÇ‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá</td></tr><tr><td>train/rewards/margins</td><td>‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÜ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÑ‚ñÑ</td></tr><tr><td>train/rewards/rejected</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñÉ‚ñÑ‚ñÜ‚ñÅ‚ñà‚ñÖ‚ñÜ‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñá‚ñÑ‚ñÅ‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/log_odds_chosen</td><td>0.14507</td></tr><tr><td>eval/log_odds_ratio</td><td>-0.78462</td></tr><tr><td>eval/logits/chosen</td><td>10.71277</td></tr><tr><td>eval/logits/rejected</td><td>11.31501</td></tr><tr><td>eval/logps/chosen</td><td>-1.82675</td></tr><tr><td>eval/logps/rejected</td><td>-1.95402</td></tr><tr><td>eval/loss</td><td>2.01164</td></tr><tr><td>eval/nll_loss</td><td>1.93317</td></tr><tr><td>eval/rewards/accuracies</td><td>0.51</td></tr><tr><td>eval/rewards/chosen</td><td>-0.18267</td></tr><tr><td>eval/rewards/margins</td><td>0.01273</td></tr><tr><td>eval/rewards/rejected</td><td>-0.1954</td></tr><tr><td>eval/runtime</td><td>77.5368</td></tr><tr><td>eval/samples_per_second</td><td>12.897</td></tr><tr><td>eval/steps_per_second</td><td>1.612</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>0.06283</td></tr><tr><td>train/global_step</td><td>122</td></tr><tr><td>train/grad_norm</td><td>3.28017</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/log_odds_chosen</td><td>0.14229</td></tr><tr><td>train/log_odds_ratio</td><td>-0.75302</td></tr><tr><td>train/logits/chosen</td><td>10.93422</td></tr><tr><td>train/logits/rejected</td><td>11.48959</td></tr><tr><td>train/logps/chosen</td><td>-1.76824</td></tr><tr><td>train/logps/rejected</td><td>-1.88168</td></tr><tr><td>train/loss</td><td>7.2768</td></tr><tr><td>train/nll_loss</td><td>1.7439</td></tr><tr><td>train/rewards/accuracies</td><td>0.59375</td></tr><tr><td>train/rewards/chosen</td><td>-0.17682</td></tr><tr><td>train/rewards/margins</td><td>0.01134</td></tr><tr><td>train/rewards/rejected</td><td>-0.18817</td></tr><tr><td>train_loss</td><td>8.15423</td></tr><tr><td>train_runtime</td><td>1217.7164</td></tr><tr><td>train_samples_per_second</td><td>3.189</td></tr><tr><td>train_steps_per_second</td><td>0.1</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run-20250226-0450-fb827d</strong> at: <a href='https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo/runs/k53vxw4w' target=\"_blank\">https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo/runs/k53vxw4w</a><br> View project at: <a href='https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo' target=\"_blank\">https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo</a><br>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250226_045006-k53vxw4w/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pushing model to hub...\n",
            "Error pushing to hub: name 'wandb' is not defined\n",
            "Attempting manual push...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edda9cd949264c52a4ec72086c7dbc75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/538M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5e7b9aa11af445c9c6a035e605b4939",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/5.21k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Manual push completed!\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    print(\"Pushing model to hub...\")\n",
        "    trainer.push_to_hub(tags=finetune_tags)\n",
        "    print(\"Successfully pushed to hub!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error pushing to hub: {str(e)}\")\n",
        "    # Alternative manual push\n",
        "    print(\"Attempting manual push...\")\n",
        "    model.push_to_hub(finetune_name, tags=finetune_tags)\n",
        "    tokenizer.push_to_hub(finetune_name, tags=finetune_tags)\n",
        "    print(\"Manual push completed!\")\n",
        "\n",
        "# Finally, close wandb\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'wandb' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[47], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save to the huggingface hub if login (HF_TOKEN is set)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# if os.getenv(\"HF_TOKEN\"):\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinetune_tags\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/matthew/interpretable-fine-tuning/.venv/lib/python3.11/site-packages/transformers/trainer.py:4788\u001b[0m, in \u001b[0;36mTrainer.push_to_hub\u001b[0;34m(self, commit_message, blocking, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m   4785\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m model_tag \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   4786\u001b[0m             kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(model_tag)\n\u001b[0;32m-> 4788\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model_card\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;66;03m# Wait for the current upload to be finished.\u001b[39;00m\n\u001b[1;32m   4791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finish_current_push()\n",
            "File \u001b[0;32m~/matthew/interpretable-fine-tuning/.venv/lib/python3.11/site-packages/trl/trainer/orpo_trainer.py:1091\u001b[0m, in \u001b[0;36mORPOTrainer.create_model_card\u001b[0;34m(self, model_name, dataset_name, tags)\u001b[0m\n\u001b[1;32m   1075\u001b[0m     tags\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsloth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1077\u001b[0m citation \u001b[38;5;241m=\u001b[39m textwrap\u001b[38;5;241m.\u001b[39mdedent(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;124m@article\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mhong2024orpo,\u001b[39m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;124m    title        = \u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124mORPO: Monolithic Preference Optimization without Reference Model}},\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;124m    eprint       = \u001b[39m\u001b[38;5;132;01m{arXiv:2403.07691}\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m   1085\u001b[0m model_card \u001b[38;5;241m=\u001b[39m generate_model_card(\n\u001b[1;32m   1086\u001b[0m     base_model\u001b[38;5;241m=\u001b[39mbase_model,\n\u001b[1;32m   1087\u001b[0m     model_name\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[1;32m   1088\u001b[0m     hub_model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhub_model_id,\n\u001b[1;32m   1089\u001b[0m     dataset_name\u001b[38;5;241m=\u001b[39mdataset_name,\n\u001b[1;32m   1090\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m-> 1091\u001b[0m     wandb_url\u001b[38;5;241m=\u001b[39mwandb\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mget_url() \u001b[38;5;28;01mif\u001b[39;00m is_wandb_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mwandb\u001b[49m\u001b[38;5;241m.\u001b[39mrun \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1092\u001b[0m     comet_url\u001b[38;5;241m=\u001b[39mget_comet_experiment_url(),\n\u001b[1;32m   1093\u001b[0m     trainer_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mORPO\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1094\u001b[0m     trainer_citation\u001b[38;5;241m=\u001b[39mcitation,\n\u001b[1;32m   1095\u001b[0m     paper_title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mORPO: Monolithic Preference Optimization without Reference Model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1096\u001b[0m     paper_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2403.07691\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1097\u001b[0m )\n\u001b[1;32m   1099\u001b[0m model_card\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39moutput_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREADME.md\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'wandb' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# # Save to the huggingface hub if login (HF_TOKEN is set)\n",
        "# # if os.getenv(\"HF_TOKEN\"):\n",
        "# trainer.push_to_hub(tags=finetune_tags)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVCymxp_-LGC"
      },
      "source": [
        "## üíê You're done!\n",
        "\n",
        "This notebook provided a step-by-step guide to fine-tuning the `HuggingFaceTB/SmolLM2-135M` model using the `ORPOTrainer`. By following these steps, you can adapt the model to perform specific tasks more effectively. If you want to carry on working on this course, here are steps you could try out:\n",
        "\n",
        "- Try this notebook on a harder difficulty\n",
        "- Review a colleagues PR\n",
        "- Improve the course material via an Issue or PR."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
