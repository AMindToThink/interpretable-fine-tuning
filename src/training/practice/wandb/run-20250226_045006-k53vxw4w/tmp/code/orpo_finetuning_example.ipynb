{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_Yuy55M-LF-"
      },
      "source": [
        "# Preference Alignment with Odds Ratio Preference Optimization (ORPO)\n",
        "\n",
        "This notebook will guide you through the process of fine-tuning a language model using Odds Ratio Preference Optimization (ORPO). We will use the SmolLM2-135M model which has **not** been through SFT training, so it is not compatible with DPO. This means, you cannot use the model you trained in [1_instruction_tuning](../../1_instruction_tuning/notebooks/sft_finetuning_example.ipynb).\n",
        "\n",
        "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
        "     <h2 style='margin: 0;color:blue'>Exercise: Aligning SmolLM2 with ORPOTrainer</h2>\n",
        "     <p>Take a dataset from the Hugging Face hub and align a model on it. </p>\n",
        "     <p><b>Difficulty Levels</b></p>\n",
        "     <p>ğŸ¢ Use the `trl-lib/ultrafeedback_binarized` dataset</p>\n",
        "     <p>ğŸ• Try out the `argilla/ultrafeedback-binarized-preferences` dataset</p>\n",
        "     <p>ğŸ¦ Try on a subset of mlabonne's `orpo-dpo-mix-40k` dataset</p>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hkHn6rQ-LF_"
      },
      "source": [
        "## Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwNxh0pCQhfI",
        "outputId": "e4c288e1-2fa3-4717-d9dd-ae3ec0b91e3b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        ")\n",
        "from trl import ORPOConfig, ORPOTrainer, setup_chat_format\n",
        "\n",
        "# Authenticate to Hugging Face\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(token=input(\"Please give your huggingface key: \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged in as: {'type': 'user', 'id': '66f9ceca46d413c380d53ff3', 'name': 'AMindToThink', 'fullname': 'Matthew Khoriaty', 'email': 'matthewkhoriaty@gmail.com', 'emailVerified': True, 'canPay': False, 'periodEnd': None, 'isPro': False, 'avatarUrl': '/avatars/44baa1c81b0e87ac5ff27c43173423d4.svg', 'orgs': [], 'auth': {'type': 'access_token', 'accessToken': {'displayName': 'zach_AMindToThink_write', 'role': 'write', 'createdAt': '2025-02-25T21:02:51.453Z'}}}\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import whoami\n",
        "try:\n",
        "    username = whoami()\n",
        "    print(f\"Logged in as: {username}\")\n",
        "except Exception as e:\n",
        "    print(\"Not logged in or error retrieving user information.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbtXToR--LGA"
      },
      "source": [
        "## Format dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AQT08S8j-LGA",
        "outputId": "23d86e61-f7ba-4d65-92be-7382f4d4d7f3"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "\n",
        "# TODO: ğŸ¦ğŸ• change the dataset to one of your choosing\n",
        "dataset = load_dataset(path=\"trl-lib/ultrafeedback_binarized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "u5YJ0Ttm-LGB"
      },
      "outputs": [],
      "source": [
        "# TODO: ğŸ• If your dataset is not represented as conversation lists, you can use the `process_dataset` function to convert it.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKzUyZOI-LGB"
      },
      "source": [
        "## Define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "w2kGBNStQoUd"
      },
      "outputs": [],
      "source": [
        "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
        "\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        ")\n",
        "assert device == 'cuda'\n",
        "# Model to fine-tune\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    pretrained_model_name_or_path=model_name,\n",
        "    torch_dtype=torch.float32,\n",
        ").to(device)\n",
        "model.config.use_cache = False\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model, tokenizer = setup_chat_format(model, tokenizer)\n",
        "\n",
        "# Set our name for the finetune to be saved &/ uploaded to\n",
        "finetune_name = \"SmolLM2-FT-ORPO_example\"\n",
        "finetune_tags = [\"smol-course\", \"module_1\"]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jjmt0Pc1-LGB"
      },
      "source": [
        "## Train model with ORPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "AWDwJe7_Qqgb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cs29824/matthew/interpretable-fine-tuning/.venv/lib/python3.11/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "orpo_args = ORPOConfig(\n",
        "    # Small learning rate to prevent catastrophic forgetting\n",
        "    learning_rate=8e-6,\n",
        "    # Linear learning rate decay over training\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    # Maximum combined length of prompt + completion\n",
        "    max_length=1024,\n",
        "    # Maximum length for input prompts\n",
        "    max_prompt_length=512,\n",
        "    # Controls weight of the odds ratio loss (Î» in paper)\n",
        "    beta=0.1,\n",
        "    # Batch size for training\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    # Helps with training stability by accumulating gradients before updating\n",
        "    gradient_accumulation_steps=4,\n",
        "    # Memory-efficient optimizer for CUDA, falls back to adamw_torch for CPU/MPS\n",
        "    optim=\"paged_adamw_8bit\" if device == \"cuda\" else \"adamw_torch\",\n",
        "    # Number of training epochs\n",
        "    # num_train_epochs=1,\n",
        "    # When to run evaluation\n",
        "    evaluation_strategy=\"steps\",\n",
        "    # Evaluate every 20% of training\n",
        "    eval_steps=0.2,\n",
        "    # Log metrics every step\n",
        "    logging_steps=1,\n",
        "    # Gradual learning rate warmup\n",
        "    warmup_steps=10,\n",
        "    # Disable external logging\n",
        "    report_to=\"wandb\",\n",
        "    # Where to save model/checkpoints\n",
        "    output_dir=\"./results/\",\n",
        "    # Enable MPS (Metal Performance Shaders) if available\n",
        "    use_mps_device=device == \"mps\",\n",
        "    hub_model_id=finetune_name,\n",
        "    # bf16=True,\n",
        "    num_train_epochs=(1/4*.25),# I decided to target 15 minutes for this example. 1 epochs / 4 hours times .25 hours \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "JUTYdQmf-LGB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cs29824/matthew/interpretable-fine-tuning/.venv/lib/python3.11/site-packages/trl/trainer/orpo_trainer.py:275: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
            "  warnings.warn(\n",
            "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
          ]
        }
      ],
      "source": [
        "trainer = ORPOTrainer(\n",
        "    model=model,\n",
        "    args=orpo_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    processing_class=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>train/grad_norm</td><td>â–†â–‡â–‡â–…â–†â–†â–‡â–‡â–‡â–…â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–„â–…â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/log_odds_chosen</td><td>â–„â–…â–‡â–…â–ƒâ–‡â–ƒâ–†â–â–‡â–„â–…â–ˆâ–ƒâ–…â–„â–ˆâ–†â–„â–‚â–„â–ƒâ–ˆâ–†â–…â–…â–†</td></tr><tr><td>train/log_odds_ratio</td><td>â–„â–ƒâ–ˆâ–†â–„â–‡â–ƒâ–…â–â–‡â–ƒâ–…â–‡â–ƒâ–…â–…â–ˆâ–†â–„â–â–…â–„â–‡â–‡â–…â–‡â–†</td></tr><tr><td>train/logits/chosen</td><td>â–†â–„â–ƒâ–†â–‡â–„â–‡â–‡â–â–†â–…â–ˆâ–…â–†â–…â–â–…â–‚â–„â–‡â–†â–‚â–„â–†â–ƒâ–…â–ƒ</td></tr><tr><td>train/logits/rejected</td><td>â–†â–„â–„â–ˆâ–…â–„â–…â–ˆâ–‚â–…â–„â–‡â–ˆâ–â–‚â–â–…â–‚â–ƒâ–„â–…â–‚â–…â–„â–â–„â–ƒ</td></tr><tr><td>train/logps/chosen</td><td>â–†â–‚â–…â–„â–„â–ˆâ–„â–…â–‚â–†â–…â–â–†â–„â–†â–†â–‡â–†â–â–„â–†â–‡â–‡â–‡â–†â–†â–ˆ</td></tr><tr><td>train/logps/rejected</td><td>â–†â–â–â–„â–†â–…â–…â–ƒâ–†â–ƒâ–…â–â–â–†â–„â–†â–ƒâ–„â–‚â–‡â–†â–ˆâ–ƒâ–…â–…â–…â–‡</td></tr><tr><td>train/loss</td><td>â–â–…â–„â–…â–‚â–ƒâ–…â–…â–‚â–ˆâ–„â–„â–…â–…â–ƒâ–‚â–‚â–…â–…â–‚â–†â–…â–ƒâ–„â–…â–„â–‚</td></tr><tr><td>train/nll_loss</td><td>â–â–…â–„â–…â–â–ƒâ–…â–…â–‚â–ˆâ–„â–„â–…â–…â–ƒâ–‚â–‚â–„â–„â–â–…â–„â–ƒâ–„â–…â–„â–‚</td></tr><tr><td>train/rewards/accuracies</td><td>â–†â–…â–†â–…â–â–†â–â–†â–â–ˆâ–„â–…â–†â–â–ƒâ–ˆâ–‡â–…â–†â–‚â–…â–…â–„â–…â–„â–…â–‡</td></tr><tr><td>train/rewards/chosen</td><td>â–†â–‚â–…â–„â–„â–ˆâ–„â–…â–‚â–†â–…â–â–†â–„â–†â–†â–‡â–†â–â–„â–†â–‡â–‡â–‡â–†â–†â–ˆ</td></tr><tr><td>train/rewards/margins</td><td>â–„â–…â–‡â–…â–ƒâ–‡â–ƒâ–†â–â–‡â–„â–„â–ˆâ–ƒâ–…â–„â–ˆâ–†â–„â–‚â–„â–ƒâ–ˆâ–†â–…â–†â–…</td></tr><tr><td>train/rewards/rejected</td><td>â–†â–â–â–„â–†â–…â–…â–ƒâ–†â–ƒâ–…â–â–â–†â–„â–†â–ƒâ–„â–‚â–‡â–†â–ˆâ–ƒâ–…â–…â–…â–‡</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>0.0139</td></tr><tr><td>train/global_step</td><td>27</td></tr><tr><td>train/grad_norm</td><td>3.44195</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/log_odds_chosen</td><td>0.22409</td></tr><tr><td>train/log_odds_ratio</td><td>-0.72773</td></tr><tr><td>train/logits/chosen</td><td>12.52754</td></tr><tr><td>train/logits/rejected</td><td>13.47893</td></tr><tr><td>train/logps/chosen</td><td>-1.88092</td></tr><tr><td>train/logps/rejected</td><td>-2.05461</td></tr><tr><td>train/loss</td><td>8.3341</td></tr><tr><td>train/nll_loss</td><td>2.01075</td></tr><tr><td>train/rewards/accuracies</td><td>0.625</td></tr><tr><td>train/rewards/chosen</td><td>-0.18809</td></tr><tr><td>train/rewards/margins</td><td>0.01737</td></tr><tr><td>train/rewards/rejected</td><td>-0.20546</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run-20250226-0444-1a02f5</strong> at: <a href='https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo/runs/zwxwsmhw' target=\"_blank\">https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo/runs/zwxwsmhw</a><br> View project at: <a href='https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo' target=\"_blank\">https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo</a><br>Synced 6 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250226_044418-zwxwsmhw/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/cs29824/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/cs29824/matthew/interpretable-fine-tuning/src/training/practice/wandb/run-20250226_045006-k53vxw4w</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo/runs/k53vxw4w' target=\"_blank\">run-20250226-0450-fb827d</a></strong> to <a href='https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo' target=\"_blank\">https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo/runs/k53vxw4w' target=\"_blank\">https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo/runs/k53vxw4w</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/matthewkhoriaty-northwestern-university/smollm2-orpo/runs/k53vxw4w?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f4bc99cbf10>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "from datetime import datetime\n",
        "import uuid\n",
        "wandb.finish()\n",
        "if not os.getenv(\"WANDB_API_KEY\"):\n",
        "    wandb.login(key=input(\"Please enter your W&B API key: \"))\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.init(\n",
        "    project=\"smollm2-orpo\",\n",
        "    name=f\"run-{datetime.now().strftime('%Y%m%d-%H%M')}-{uuid.uuid4().hex[:6]}\",\n",
        "    tags=finetune_tags\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mRSTqv6-LGC"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='76' max='122' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 76/122 11:46 < 07:18, 0.10 it/s, Epoch 0.04/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "      <th>Rewards/chosen</th>\n",
              "      <th>Rewards/rejected</th>\n",
              "      <th>Rewards/accuracies</th>\n",
              "      <th>Rewards/margins</th>\n",
              "      <th>Logps/rejected</th>\n",
              "      <th>Logps/chosen</th>\n",
              "      <th>Logits/rejected</th>\n",
              "      <th>Logits/chosen</th>\n",
              "      <th>Nll Loss</th>\n",
              "      <th>Log Odds Ratio</th>\n",
              "      <th>Log Odds Chosen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>8.878600</td>\n",
              "      <td>2.063274</td>\n",
              "      <td>78.129300</td>\n",
              "      <td>12.799000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>-0.194836</td>\n",
              "      <td>-0.208181</td>\n",
              "      <td>0.522000</td>\n",
              "      <td>0.013346</td>\n",
              "      <td>-2.081815</td>\n",
              "      <td>-1.948357</td>\n",
              "      <td>12.274585</td>\n",
              "      <td>11.579242</td>\n",
              "      <td>1.981609</td>\n",
              "      <td>-0.816654</td>\n",
              "      <td>0.150561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>8.694100</td>\n",
              "      <td>2.034441</td>\n",
              "      <td>77.904000</td>\n",
              "      <td>12.836000</td>\n",
              "      <td>1.605000</td>\n",
              "      <td>-0.188239</td>\n",
              "      <td>-0.200956</td>\n",
              "      <td>0.512000</td>\n",
              "      <td>0.012717</td>\n",
              "      <td>-2.009562</td>\n",
              "      <td>-1.882390</td>\n",
              "      <td>11.899893</td>\n",
              "      <td>11.256330</td>\n",
              "      <td>1.954384</td>\n",
              "      <td>-0.800572</td>\n",
              "      <td>0.144660</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 63/125 00:38 < 00:38, 1.61 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.train()  # Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Save the model\n",
        "trainer.save_model(f\"./{finetune_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Save to the huggingface hub if login (HF_TOKEN is set)\n",
        "if os.getenv(\"HF_TOKEN\"):\n",
        "    trainer.push_to_hub(tags=finetune_tags)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVCymxp_-LGC"
      },
      "source": [
        "## ğŸ’ You're done!\n",
        "\n",
        "This notebook provided a step-by-step guide to fine-tuning the `HuggingFaceTB/SmolLM2-135M` model using the `ORPOTrainer`. By following these steps, you can adapt the model to perform specific tasks more effectively. If you want to carry on working on this course, here are steps you could try out:\n",
        "\n",
        "- Try this notebook on a harder difficulty\n",
        "- Review a colleagues PR\n",
        "- Improve the course material via an Issue or PR."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
