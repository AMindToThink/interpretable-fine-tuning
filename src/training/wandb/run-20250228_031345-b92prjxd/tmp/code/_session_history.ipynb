{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "849126ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "# YOU HAVE TO SET CUDA_VISIBLE_DEVICES BEFORE DOING ANY IMPORTS OF cuda-related packages! https://discuss.pytorch.org/t/setting-visible-devices-with-distributed-data-parallel/93230\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] ='0'\n",
    "import torch\n",
    "print(torch.cuda.device_count())  # Should print 1, but doesn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce0b6f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Import libraries\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from trl import ORPOConfig, ORPOTrainer, setup_chat_format\n",
    "from sae_lens import HookedSAETransformer, SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edba9e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Import our custom ISAERFT components\n",
    "try:\n",
    "    # When imported as a module\n",
    "    from model_components.IsaerftConfig import IsaerftConfig\n",
    "    from model_components.IsaerftPeft import IsaerftPeft\n",
    "except ImportError:\n",
    "    # When run directly as a script\n",
    "    import sys\n",
    "    import os\n",
    "    # Add the parent directory to the path\n",
    "    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "    from model_components.IsaerftConfig import IsaerftConfig\n",
    "    from model_components.IsaerftPeft import IsaerftPeft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a990e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Authenticate to Hugging Face\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token=os.environ['HUGGINGFACE_WRITE_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab0008ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Load dataset\n",
    "dataset = load_dataset(path=\"trl-lib/ultrafeedback_binarized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c856bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Define the model\n",
    "model_name = \"EleutherAI/pythia-70m-deduped\" \n",
    "from datetime import datetime\n",
    "import uuid\n",
    "run_name=f\"run-{datetime.now().strftime('%Y%m%d-%H%M')}-{uuid.uuid4().hex[:6]}\"\n",
    "\n",
    "# Get the actual device that CUDA is using\n",
    "if torch.cuda.is_available():\n",
    "    # Get the current device that's actually being used\n",
    "    device = f\"cuda:{torch.cuda.current_device()}\"\n",
    "else:\n",
    "    device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "assert 'cuda' in device\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63c5c6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Model to fine-tune\n",
    "model = HookedSAETransformer.from_pretrained(\n",
    "    model_name,\n",
    "    # torch_dtype=torch.float32,\n",
    "    # device_map=device\n",
    ").to(device)\n",
    "# model.config.use_cache = False\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8f45a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "chat_template = \"\"\"{% for message in messages %}\n",
    "{% if message['role'] == 'user' %}\n",
    "### Instruction:\n",
    "{{ message['content'] }}\n",
    "{% elif message['role'] == 'assistant' %}\n",
    "### Response:\n",
    "{{ message['content'] }}\n",
    "{% endif %}\n",
    "{% endfor %}\n",
    "{% if add_generation_prompt %}\n",
    "### Response:\n",
    "{% endif %}\"\"\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "tokenizer.chat_template = chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3340828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# non_hooked_model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2-2b\").to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64356ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# del non_hooked_model\n",
    "# chat = [\n",
    "#     { \"role\": \"user\", \"content\": \"Write a hello world program\" },\n",
    "# ]\n",
    "# prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "# print(prompt)\n",
    "# #%%\n",
    "# _, tokenizer = setup_chat_format(non_hooked_model, tokenizer) # TODO: Figure out if this is a problem that I'm not applying the chat format to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4442994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Apply ISAERFT to the model\n",
    "from sae_lens import SAE\n",
    "\n",
    "release = \"pythia-70m-deduped-res-sm\"\n",
    "sae_id = \"blocks.4.hook_resid_post\"\n",
    "isaerft_config = IsaerftConfig(\n",
    "    target_hooks=[\n",
    "        (release, sae_id),\n",
    "    ],\n",
    "    depth=-1  # Bias-only for simplicity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a004c32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Apply the ISAERFT adapter\n",
    "model = IsaerftPeft(model, isaerft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc36c60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# model, tokenizer = setup_chat_format(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8e2491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Set our name for the finetune to be saved &/ uploaded to\n",
    "finetune_name = \"PYTHIA-FT-ORPO-ISAERFT_\"+run_name\n",
    "finetune_tags = [\"smol-course\", \"module_1\", \"isaerft\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c3dbf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Train model with ORPO\n",
    "orpo_args = ORPOConfig(\n",
    "    # Small learning rate to prevent catastrophic forgetting\n",
    "    learning_rate=8e-6,\n",
    "    # Linear learning rate decay over training\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    # Maximum combined length of prompt + completion\n",
    "    max_length=1024,\n",
    "    # Maximum length for input prompts\n",
    "    max_prompt_length=512,\n",
    "    # Controls weight of the odds ratio loss (Î» in paper)\n",
    "    beta=0.1,\n",
    "    # Batch size for training\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    # Helps with training stability by accumulating gradients before updating\n",
    "    gradient_accumulation_steps=8,\n",
    "    # Memory-efficient optimizer for CUDA, falls back to adamw_torch for CPU/MPS\n",
    "    optim=\"paged_adamw_8bit\" if (\"cuda\" in device)else \"adamw_torch\",\n",
    "    # When to run evaluation\n",
    "    eval_strategy=\"steps\",\n",
    "    # Evaluate every 20% of training\n",
    "    eval_steps=0.2,\n",
    "    # Log metrics every step\n",
    "    logging_steps=1,\n",
    "    # Gradual learning rate warmup\n",
    "    warmup_steps=10,\n",
    "    # Disable external logging\n",
    "    report_to=\"wandb\",\n",
    "    # Where to save model/checkpoints\n",
    "    output_dir=\"./results/orpo_isaerft/\"+run_name,\n",
    "    # Enable MPS (Metal Performance Shaders) if available\n",
    "    use_mps_device=device == \"mps\",\n",
    "    hub_model_id=finetune_name,\n",
    "    # Training for a shorter time for this example\n",
    "    num_train_epochs=(1/4*.25),\n",
    "    # Ensure device placement is correct\n",
    "    no_cuda=False,\n",
    "    dataloader_pin_memory=False,\n",
    "    dataloader_drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15819d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<wandb.sdk.wandb_run.Run at 0x7fee4506f490>"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/cs29824/matthew/interpretable-fine-tuning/src/training/wandb/run-20250228_031345-b92prjxd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/matthewkhoriaty-northwestern-university/pythia70m-orpo-isaerft/runs/b92prjxd' target=\"_blank\">run-20250228-0313-708d76</a></strong> to <a href='https://wandb.ai/matthewkhoriaty-northwestern-university/pythia70m-orpo-isaerft' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/matthewkhoriaty-northwestern-university/pythia70m-orpo-isaerft' target=\"_blank\">https://wandb.ai/matthewkhoriaty-northwestern-university/pythia70m-orpo-isaerft</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/matthewkhoriaty-northwestern-university/pythia70m-orpo-isaerft/runs/b92prjxd' target=\"_blank\">https://wandb.ai/matthewkhoriaty-northwestern-university/pythia70m-orpo-isaerft/runs/b92prjxd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%\n",
    "# Initialize wandb\n",
    "import wandb\n",
    "\n",
    "# Make sure any previous wandb run is properly closed\n",
    "wandb.finish()\n",
    "wandb.login(key=os.environ['WANDB_KEY'])\n",
    "\n",
    "wandb.init(\n",
    "    project=\"pythia70m-orpo-isaerft\",\n",
    "    name=run_name,\n",
    "    tags=finetune_tags\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0806dc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Create the trainer\n",
    "trainer = ORPOTrainer(\n",
    "    model=model,\n",
    "    args=orpo_args,\n",
    "    train_dataset=dataset[\"train\"].select(range(100)),\n",
    "    eval_dataset=dataset[\"test\"].select(range(10)),\n",
    "    processing_class=tokenizer,\n",
    "    # peft_config=isaerft_config, # don't include this; it is one or the other: model is a HookedSAETransformer and peft_config is used to transform it, or model is an IsaerftPeft and no peft_config needed\n",
    "    # label_names=[\"labels\"],  # This is the standard label name for causal language models\n",
    "    # dataset_num_proc=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66ee7f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainOutput(global_step=1, training_loss=63.85625076293945, metrics={'train_runtime': 2.3547, 'train_samples_per_second': 2.654, 'train_steps_per_second': 0.425, 'total_flos': 0.0, 'train_loss': 63.85625076293945, 'epoch': 0.16})"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/1 : < :, Epoch 0.16/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/1 : < :, Epoch 0.16/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/5 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/1 : < :, Epoch 0.16/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/5 00:00 < 00:00, 15.23 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/1 : < :, Epoch 0.16/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/5 00:00 < 00:00, 10.84 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/1 : < :, Epoch 0.16/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/5 00:00 < 00:00, 12.16 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/1 : < :, Epoch 0.16/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/1 : < :, Epoch 0.16/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "      <th>Steps Per Second</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Logits/rejected</th>\n",
       "      <th>Logits/chosen</th>\n",
       "      <th>Nll Loss</th>\n",
       "      <th>Log Odds Ratio</th>\n",
       "      <th>Log Odds Chosen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>63.856300</td>\n",
       "      <td>6.971425</td>\n",
       "      <td>0.476100</td>\n",
       "      <td>21.003000</td>\n",
       "      <td>10.501000</td>\n",
       "      <td>-2.733371</td>\n",
       "      <td>-6.284737</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3.551366</td>\n",
       "      <td>-62.847370</td>\n",
       "      <td>-27.333710</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>5.843417</td>\n",
       "      <td>-11.280080</td>\n",
       "      <td>35.490234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "      <th>Steps Per Second</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Logits/rejected</th>\n",
       "      <th>Logits/chosen</th>\n",
       "      <th>Nll Loss</th>\n",
       "      <th>Log Odds Ratio</th>\n",
       "      <th>Log Odds Chosen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>63.856300</td>\n",
       "      <td>6.971425</td>\n",
       "      <td>0.476100</td>\n",
       "      <td>21.003000</td>\n",
       "      <td>10.501000</td>\n",
       "      <td>-2.733371</td>\n",
       "      <td>-6.284737</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3.551366</td>\n",
       "      <td>-62.847370</td>\n",
       "      <td>-27.333710</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>5.843417</td>\n",
       "      <td>-11.280080</td>\n",
       "      <td>35.490234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%\n",
    "# Train the model\n",
    "# b /home/cs29824/matthew/interpretable-fine-tuning/.venv/lib/python3.11/site-packages/transformer_lens/components/embed.py:34\n",
    "# import pdb;pdb.set_trace()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8a2ffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Save the model\n",
    "trainer.save_model(f\"./{finetune_name}\")\n",
    "\n",
    "# Finish wandb logging\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
